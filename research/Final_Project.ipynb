{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4f2b772",
      "metadata": {
        "id": "f4f2b772"
      },
      "source": [
        "# 1. IMPORT DEPENDENCES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "72553b01",
      "metadata": {
        "id": "72553b01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 23:08:57.060441: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-26 23:08:57.093663: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 23:08:57.093707: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 23:08:57.093747: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 23:08:57.101126: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-26 23:08:57.101475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-26 23:08:58.103778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50,DenseNet201, EfficientNetB4\n",
        "from tensorflow.keras.applications import resnet, densenet, efficientnet\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import PIL\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2044507b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2044507b",
        "outputId": "c9e57ff1-0b1d-4110-9fdb-4616d00e2bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: np-utils in /workspaces/project/env/lib/python3.9/site-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /workspaces/project/env/lib/python3.9/site-packages (from np-utils) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install np-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12a6a37c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip uninstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3638360f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /workspaces/project/env/lib/python3.9/site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /workspaces/project/env/lib/python3.9/site-packages (from opencv-python) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8c0a3bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f8c0a3bc",
        "outputId": "c1210a3c-703d-4404-c71d-f26dcfc2fa6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.14.0 in /workspaces/project/env/lib/python3.9/site-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Collecting numpy>=1.23.5 (from tensorflow==2.14.0)\n",
            "  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (4.25.3)\n",
            "Requirement already satisfied: setuptools in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (68.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /workspaces/project/env/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /workspaces/project/env/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.29.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /workspaces/project/env/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /workspaces/project/env/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /workspaces/project/env/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /workspaces/project/env/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /workspaces/project/env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /workspaces/project/env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /workspaces/project/env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /workspaces/project/env/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /workspaces/project/env/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (6.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/project/env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /workspaces/project/env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/project/env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/project/env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /workspaces/project/env/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /workspaces/project/env/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.18.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /workspaces/project/env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /workspaces/project/env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n",
            "Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "mehKob80-3wU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mehKob80-3wU",
        "outputId": "567adcd0-b8b5-4d95-fca9-6f1ff3794626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.14.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /workspaces/project/env/lib/python3.9/site-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fa909bee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fa909bee",
        "outputId": "094bf09e-cc58-4b3a-fff8-2a5f35dda2df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/project/research'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9COgkvK5lu7L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9COgkvK5lu7L",
        "outputId": "4d792f81-b6a4-4f16-8ecb-6bc726234d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ProjectChest\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/ProjectChest/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "71c017fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71c017fb",
        "outputId": "c2c5eeee-b9d7-49f5-850d-f9039527aeb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chest/Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\n",
            "chest/Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\n",
            "chest/Data/train/normal\n",
            "chest/Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = \"chest/Data/train\"\n",
        "for files in os.listdir(path):\n",
        "    print(os.path.join(path,files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "54f63bc8",
      "metadata": {
        "id": "54f63bc8"
      },
      "outputs": [],
      "source": [
        "train_path = \"chest/Data/train\"\n",
        "valid_path = \"chest/Data/valid\"\n",
        "test_path = \"chest/Data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "C5LeKgRaldPE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5LeKgRaldPE",
        "outputId": "1ed935e8-bb26-4d2a-8d57-d1b75bf4ae60"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "518ec66f",
      "metadata": {
        "id": "518ec66f"
      },
      "outputs": [],
      "source": [
        "image_paths = ['chest/Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa',\n",
        "'chest/Data/train/normal',\n",
        "'chest/Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa',\n",
        "'chest/Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib']\n",
        "\n",
        "def load_images(image_paths = image_paths, n=36):\n",
        "    # Load the images from disk.\n",
        "    images = []\n",
        "    for i in range(len(image_paths)):\n",
        "        images_ = [cv2.imread(image_paths[i]+'/'+path) for path in os.listdir(image_paths[i])[:int(n/4)]]\n",
        "        images.append(images_)\n",
        "    # Convert to a numpy array and return it.\n",
        "    sample = np.asarray(images)\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b24d2a3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "b24d2a3c",
        "outputId": "370d4bc5-46e6-4c5d-d7fa-ce88033118d7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (4, 9) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mload_images\u001b[0;34m(image_paths, n)\u001b[0m\n\u001b[1;32m     11\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(images_)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Convert to a numpy array and return it.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (4, 9) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "sample = load_images()\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "l = 1\n",
        "shapes = []\n",
        "for i in range(sample.shape[0]):\n",
        "    for m in range(sample.shape[1]):\n",
        "        ax = fig.add_subplot(4,9,m+l,xticks = [], yticks = [])\n",
        "        ax.imshow(np.squeeze(sample[i,m]))\n",
        "        shapes.append(sample[i,m].shape)\n",
        "    l +=9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b59ec346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b59ec346",
        "outputId": "ea1c2f0a-f9da-438e-c1b4-58f9b2a42154"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'shapes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mshapes\u001b[49m)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shapes' is not defined"
          ]
        }
      ],
      "source": [
        "np.array(shapes).mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "RmvGjmfuzLgi",
      "metadata": {
        "id": "RmvGjmfuzLgi"
      },
      "outputs": [],
      "source": [
        "def define_paths(dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    folds = os.listdir(dir)\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(dir, fold)\n",
        "        filelist = os.listdir(foldpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "    return filepaths, labels\n",
        "def define_df(files, classes):\n",
        "    Fseries = pd.Series(files, name= 'filepaths')\n",
        "    Lseries = pd.Series(classes, name='labels')\n",
        "    return pd.concat([Fseries, Lseries], axis= 1)\n",
        "\n",
        "def create_df(tr_dir, val_dir, ts_dir):\n",
        "    # train dataframe\n",
        "    files, classes = define_paths(tr_dir)\n",
        "    train_df = define_df(files, classes)\n",
        "\n",
        "    # validation dataframe\n",
        "    files, classes = define_paths(val_dir)\n",
        "    valid_df = define_df(files, classes)\n",
        "    # test dataframe\n",
        "    files, classes = define_paths(ts_dir)\n",
        "    test_df = define_df(files, classes)\n",
        "    return train_df, valid_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "33843829",
      "metadata": {
        "id": "33843829"
      },
      "outputs": [],
      "source": [
        "def create_gens(train_df, valid_df, test_df, batch_size):\n",
        "    img_size = (224, 224)\n",
        "    channels = 3\n",
        "    img_shape = (img_size[0], img_size[1], channels)\n",
        "    ts_length = len(test_df)\n",
        "    test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "    test_steps = ts_length // test_batch_size\n",
        "    def scalar(img):\n",
        "        return img\n",
        "    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n",
        "    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)\n",
        "    return train_gen, valid_gen, test_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e96ee02b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e96ee02b",
        "outputId": "6d77d47a-b725-4509-cfc6-698280a86a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 613 validated image filenames belonging to 4 classes.\n",
            "Found 315 validated image filenames belonging to 4 classes.\n",
            "Found 72 validated image filenames belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Get Dataframes\n",
        "train_dir = 'chest/Data/train'\n",
        "test_dir = 'chest/Data/valid'\n",
        "valid_dir = 'chest/Data/test'\n",
        "train_df, valid_df, test_df = create_df(train_dir, valid_dir, test_dir)\n",
        "\n",
        "# Get Generators\n",
        "batch_size = 40\n",
        "train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea59ba26",
      "metadata": {
        "id": "ea59ba26"
      },
      "source": [
        "## ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9b93004f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b93004f",
        "outputId": "1902c296-7334-40ca-b88f-97c62e80e2df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 613 images belonging to 4 classes.\n",
            "Found 72 images belonging to 4 classes.\n",
            "Found 315 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "image_shape = (460,460,3)\n",
        "N_CLASSES = 4\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=resnet.preprocess_input)\n",
        "train_generator = train_datagen.flow_from_directory(train_path,\n",
        "                                                   batch_size = BATCH_SIZE,\n",
        "                                                   target_size = (460,460),\n",
        "                                                   class_mode = 'categorical')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=resnet.preprocess_input)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_path,\n",
        "                                                   batch_size = BATCH_SIZE,\n",
        "                                                   target_size = (460,460),\n",
        "                                                   class_mode = 'categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=resnet.preprocess_input)\n",
        "test_generator = test_datagen.flow_from_directory(test_path,\n",
        "                                                   batch_size = BATCH_SIZE,\n",
        "                                                   target_size = (460,460),\n",
        "                                                   class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "57f8cd03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57f8cd03",
        "outputId": "c14d784e-2a6a-4392-a979-f30cceb9e35d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 7s 0us/step\n"
          ]
        }
      ],
      "source": [
        "res_model = ResNet50(include_top=False, pooling='avg', weights='imagenet', input_shape = (image_shape))\n",
        "for layer in res_model.layers:\n",
        "    if 'conv5' not in layer.name:\n",
        "        layer.trainable = False\n",
        "# Check if all layers except conv5 layers are not trainable\n",
        "#for i, layer in enumerate(res_model.layers):\n",
        "#    print(i, layer.name, \"-\", layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4e072c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e072c2f",
        "outputId": "f699b4b0-4bb5-4bda-991c-236fca4e6bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2048)             8192      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 8196      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,604,100\n",
            "Trainable params: 14,988,292\n",
            "Non-trainable params: 8,615,808\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(res_model)\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(N_CLASSES, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cd8f7c67",
      "metadata": {
        "id": "cd8f7c67"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam(learning_rate= 0.00001)\n",
        "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "be3e285e",
      "metadata": {
        "id": "be3e285e"
      },
      "outputs": [],
      "source": [
        "checkpointer = ModelCheckpoint(filepath='./chest_CT_SCAN-ResNet50.hdf5',\n",
        "                            monitor='val_loss', verbose = 1,\n",
        "                            save_best_only=True)\n",
        "early_stopping = EarlyStopping(verbose=1, patience=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d4950d92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4950d92",
        "outputId": "f6eaa67e-d11a-4646-da13-923686a3a97b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 22:21:44.478929: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 22:21:49.031147: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 433356800 exceeds 10% of free system memory.\n",
            "2024-03-26 22:21:49.653222: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 433356800 exceeds 10% of free system memory.\n",
            "2024-03-26 22:21:49.801810: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440926208 exceeds 10% of free system memory.\n",
            "2024-03-26 22:21:49.939526: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 433356800 exceeds 10% of free system memory.\n",
            "2024-03-26 22:21:50.082337: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 433356800 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/20 [=====================>........] - ETA: 54s - loss: 2.4528 - acc: 0.3113 "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history_res = model.fit(train_generator,\n",
        "                    steps_per_epoch = 20,\n",
        "                    epochs = 100,\n",
        "                    verbose = 1,\n",
        "                    validation_data = valid_generator,\n",
        "                    callbacks = [checkpointer, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05eb1458",
      "metadata": {
        "id": "05eb1458"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gCb2q7uZANA9",
      "metadata": {
        "id": "gCb2q7uZANA9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Input, Average\n",
        "\n",
        "\n",
        "\n",
        "model= load_model('chest_CT_SCAN-ResNet50.h5')\n",
        "\n",
        "ts_length = len(test_df)\n",
        "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
        "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
        "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Validation Loss: \", valid_score[0])\n",
        "print(\"Validation Accuracy: \", valid_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54926d0d",
      "metadata": {
        "id": "54926d0d"
      },
      "source": [
        "## EfficientNetB3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7e1fc2e9",
      "metadata": {
        "id": "7e1fc2e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 23:10:49.143260: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 289013760 exceeds 10% of free system memory.\n",
            "2024-03-26 23:10:49.185587: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 289013760 exceeds 10% of free system memory.\n",
            "2024-03-26 23:10:49.279142: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 294197760 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/16 [>.............................] - ETA: 2:03 - loss: 2.2491 - accuracy: 0.2000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 23:10:50.590752: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 289013760 exceeds 10% of free system memory.\n",
            "2024-03-26 23:10:50.635273: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 289013760 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - ETA: 0s - loss: 1.2056 - accuracy: 0.5595\n",
            "Epoch 1: val_accuracy improved from -inf to 0.68254, saving model to chest_CT_SCAN-EfficientNetB3.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/project/env/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 42s 2s/step - loss: 1.2056 - accuracy: 0.5595 - val_loss: 1.3064 - val_accuracy: 0.6825\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7667\n",
            "Epoch 2: val_accuracy did not improve from 0.68254\n",
            "16/16 [==============================] - 34s 2s/step - loss: 0.5794 - accuracy: 0.7667 - val_loss: 1.4787 - val_accuracy: 0.6635\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4211 - accuracy: 0.8564\n",
            "Epoch 3: val_accuracy did not improve from 0.68254\n",
            "16/16 [==============================] - 34s 2s/step - loss: 0.4211 - accuracy: 0.8564 - val_loss: 1.3006 - val_accuracy: 0.6603\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.8858\n",
            "Epoch 4: val_accuracy improved from 0.68254 to 0.68889, saving model to chest_CT_SCAN-EfficientNetB3.h5\n",
            "16/16 [==============================] - 33s 2s/step - loss: 0.3054 - accuracy: 0.8858 - val_loss: 1.3967 - val_accuracy: 0.6889\n",
            "Epoch 5/100\n",
            "13/16 [=======================>......] - ETA: 4s - loss: 0.2660 - accuracy: 0.8966"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train the model with the added callback\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Assuming train_gen and valid_gen are your image data generators\n",
        "\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_gen.class_indices.keys()))\n",
        "\n",
        "# Create pre-trained model\n",
        "base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis=-1),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(class_count, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define filepath to save the best model\n",
        "filepath = 'chest_CT_SCAN-EfficientNetB3.h5'\n",
        "\n",
        "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with the added callback\n",
        "history = model.fit(\n",
        "    x=train_gen,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=valid_gen,\n",
        "    callbacks=[checkpoint]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cda870f",
      "metadata": {
        "id": "6cda870f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Input, Average\n",
        "\n",
        "\n",
        "\n",
        "model= load_model('chest_CT_SCAN-EfficientNetB3.h5')\n",
        "\n",
        "ts_length = len(test_df)\n",
        "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
        "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
        "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Validation Loss: \", valid_score[0])\n",
        "print(\"Validation Accuracy: \", valid_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f95e40e",
      "metadata": {
        "id": "9f95e40e"
      },
      "source": [
        "## DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7d5373d3",
      "metadata": {
        "id": "7d5373d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 613 images belonging to 4 classes.\n",
            "Found 72 images belonging to 4 classes.\n",
            "Found 315 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "image_shape = (460,460,3)\n",
        "N_CLASSES = 4\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=densenet.preprocess_input)\n",
        "train_generator = train_datagen.flow_from_directory(train_path,\n",
        "                                                   batch_size = BATCH_SIZE,\n",
        "                                                   target_size = (460,460),\n",
        "                                                   class_mode = 'categorical')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=densenet.preprocess_input)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_path,\n",
        "                                                   batch_size = BATCH_SIZE,\n",
        "                                                   target_size = (460,460),\n",
        "                                                   class_mode = 'categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=densenet.preprocess_input)\n",
        "test_generator = test_datagen.flow_from_directory(test_path,\n",
        "                                                   batch_size = BATCH_SIZE,\n",
        "                                                   target_size = (460,460),\n",
        "                                                   class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1b05b648",
      "metadata": {
        "id": "1b05b648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74836368/74836368 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "dense_model = DenseNet201(include_top=False, pooling='avg', weights='imagenet', input_shape = (image_shape))\n",
        "for layer in dense_model.layers:\n",
        "    if 'conv5' not in layer.name:\n",
        "        layer.trainable = False\n",
        "# Check if all layers except conv5 layers are not trainable\n",
        "#for i, layer in enumerate(dense_model.layers):\n",
        "#    print(i, layer.name, \"-\", layer.trainable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "aa66e435",
      "metadata": {
        "id": "aa66e435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet201 (Functional)    (None, 1920)              18321984  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1920)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1920)             7680      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 7684      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,337,348\n",
            "Trainable params: 6,990,084\n",
            "Non-trainable params: 11,347,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(dense_model)\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.6))\n",
        "model.add(Dense(N_CLASSES, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "51af36c2",
      "metadata": {
        "id": "51af36c2"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam(learning_rate= 0.00001)\n",
        "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f362ee8f",
      "metadata": {
        "id": "f362ee8f"
      },
      "outputs": [],
      "source": [
        "checkpointer = ModelCheckpoint(filepath='./chest_CT_SCAN-DenseNet201.hdf5',\n",
        "                            monitor='val_loss', verbose = 1,\n",
        "                            save_best_only=True)\n",
        "early_stopping = EarlyStopping(verbose=1, patience=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7e73f60e",
      "metadata": {
        "id": "7e73f60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 22:26:41.702722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - ETA: 0s - loss: 1.3077 - acc: 0.4176 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 22:30:56.692203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 1.38556, saving model to ./chest_CT_SCAN-DenseNet201.hdf5\n",
            "20/20 [==============================] - 279s 13s/step - loss: 1.3077 - acc: 0.4176 - val_loss: 1.3856 - val_acc: 0.3472\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_dense \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m/workspaces/project/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history_dense = model.fit(train_generator,\n",
        "                    steps_per_epoch = 20,\n",
        "                    epochs = 100,\n",
        "                    verbose = 1,\n",
        "                    validation_data = valid_generator,\n",
        "                    callbacks = [checkpointer, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c3259c9",
      "metadata": {
        "id": "4c3259c9"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6200e6",
      "metadata": {
        "id": "6e6200e6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Input, Average\n",
        "\n",
        "\n",
        "\n",
        "model= load_model('chest_CT_SCAN-DenseNet201.h5')\n",
        "\n",
        "ts_length = len(test_df)\n",
        "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
        "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
        "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Validation Loss: \", valid_score[0])\n",
        "print(\"Validation Accuracy: \", valid_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458018aa",
      "metadata": {
        "id": "458018aa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbed82f6",
      "metadata": {
        "id": "bbed82f6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9038f546",
      "metadata": {
        "id": "9038f546"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "484fc2bf",
      "metadata": {
        "id": "484fc2bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5931bf6",
      "metadata": {
        "id": "c5931bf6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d396bd",
      "metadata": {
        "id": "c4d396bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb81e1aa",
      "metadata": {
        "id": "eb81e1aa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97f898bc",
      "metadata": {
        "id": "97f898bc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04ce3d8",
      "metadata": {
        "id": "e04ce3d8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ceaf58a",
      "metadata": {
        "id": "7ceaf58a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1f2dbd",
      "metadata": {
        "id": "0d1f2dbd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e3ff75",
      "metadata": {
        "id": "e0e3ff75"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d1a9236",
      "metadata": {
        "id": "9d1a9236"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb61ede",
      "metadata": {
        "id": "9cb61ede"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058fddc9",
      "metadata": {
        "id": "058fddc9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38237a83",
      "metadata": {
        "id": "38237a83"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4a0c85",
      "metadata": {
        "id": "9b4a0c85"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "846ff684",
      "metadata": {
        "id": "846ff684"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bbd0722",
      "metadata": {
        "id": "6bbd0722"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "592e3ee3",
      "metadata": {
        "id": "592e3ee3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6e4ce8",
      "metadata": {
        "id": "ae6e4ce8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436138c0",
      "metadata": {
        "id": "436138c0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8bd6d6",
      "metadata": {
        "id": "ee8bd6d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4703635a",
      "metadata": {
        "id": "4703635a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bfc90d5",
      "metadata": {
        "id": "1bfc90d5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
