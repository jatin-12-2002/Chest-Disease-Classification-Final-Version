{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/project/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 15:19:53.378656: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-27 15:19:53.411911: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-27 15:19:53.411943: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-27 15:19:53.411977: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-27 15:19:53.418413: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-27 15:19:53.419196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 15:19:54.172010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chest-CT-Scan-data\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import shutil\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.base_model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "        \n",
    "        destination_dir = path.parent.parent.parent / \"model\"\n",
    "        if not destination_dir.exists():\n",
    "            destination_dir.mkdir(parents=True)\n",
    "\n",
    "        # Copy the file to the destination directory\n",
    "        destination_file = destination_dir / \"model.h5\"\n",
    "        shutil.copyfile(path, destination_file)\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        for layer in self.base_model.layers:\n",
    "            layer.trainable = False\n",
    "        class_count = len(list(self.train_generator.class_indices.keys()))\n",
    "        self.model = Sequential([\n",
    "                self.base_model,\n",
    "                BatchNormalization(axis=-1),\n",
    "                Dense(256, activation='relu'),\n",
    "                Dropout(0.3),\n",
    "                Dense(class_count, activation='softmax')\n",
    "            ])\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        self.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filepath = str(self.config.trained_model_path)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=[checkpoint]\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-27 15:30:49,050: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-03-27 15:30:49,052: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-27 15:30:49,052: INFO: common: created directory at: artifacts]\n",
      "[2024-03-27 15:30:49,053: INFO: common: created directory at: artifacts/training]\n",
      "Found 182 images belonging to 4 classes.\n",
      "Found 736 images belonging to 4 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 15:30:59.815442: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 115605504 exceeds 10% of free system memory.\n",
      "2024-03-27 15:30:59.853243: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 115605504 exceeds 10% of free system memory.\n",
      "2024-03-27 15:30:59.914537: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 117679104 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/46 [..............................] - ETA: 5:57 - loss: 1.3763 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 15:31:00.573282: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 115605504 exceeds 10% of free system memory.\n",
      "2024-03-27 15:31:00.604288: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 115605504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 1.3715 - accuracy: 0.3207\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36932, saving model to artifacts/training/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/project/env/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 48s 881ms/step - loss: 1.3715 - accuracy: 0.3207 - val_loss: 1.3571 - val_accuracy: 0.3693\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3434 - accuracy: 0.3465\n",
      "Epoch 2: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 34s 733ms/step - loss: 1.3434 - accuracy: 0.3465 - val_loss: 1.3496 - val_accuracy: 0.3693\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3302 - accuracy: 0.3533\n",
      "Epoch 3: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 34s 728ms/step - loss: 1.3302 - accuracy: 0.3533 - val_loss: 1.3463 - val_accuracy: 0.3693\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3228 - accuracy: 0.3587\n",
      "Epoch 4: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 723ms/step - loss: 1.3228 - accuracy: 0.3587 - val_loss: 1.3450 - val_accuracy: 0.3693\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3233 - accuracy: 0.3614\n",
      "Epoch 5: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 720ms/step - loss: 1.3233 - accuracy: 0.3614 - val_loss: 1.3453 - val_accuracy: 0.3693\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3299 - accuracy: 0.3628\n",
      "Epoch 6: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 34s 728ms/step - loss: 1.3299 - accuracy: 0.3628 - val_loss: 1.3460 - val_accuracy: 0.3693\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3281 - accuracy: 0.3573\n",
      "Epoch 7: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 724ms/step - loss: 1.3281 - accuracy: 0.3573 - val_loss: 1.3430 - val_accuracy: 0.3693\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3243 - accuracy: 0.3505\n",
      "Epoch 8: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 1.3243 - accuracy: 0.3505 - val_loss: 1.3427 - val_accuracy: 0.3693\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3381 - accuracy: 0.3696\n",
      "Epoch 9: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 723ms/step - loss: 1.3381 - accuracy: 0.3696 - val_loss: 1.3410 - val_accuracy: 0.3693\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3156 - accuracy: 0.3764\n",
      "Epoch 10: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 720ms/step - loss: 1.3156 - accuracy: 0.3764 - val_loss: 1.3387 - val_accuracy: 0.3693\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3261 - accuracy: 0.3736\n",
      "Epoch 11: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 1.3261 - accuracy: 0.3736 - val_loss: 1.3400 - val_accuracy: 0.3693\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3341 - accuracy: 0.3465\n",
      "Epoch 12: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 1.3341 - accuracy: 0.3465 - val_loss: 1.3379 - val_accuracy: 0.3693\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3336 - accuracy: 0.3723\n",
      "Epoch 13: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 1.3336 - accuracy: 0.3723 - val_loss: 1.3360 - val_accuracy: 0.3693\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3346 - accuracy: 0.3478\n",
      "Epoch 14: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 723ms/step - loss: 1.3346 - accuracy: 0.3478 - val_loss: 1.3310 - val_accuracy: 0.3693\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3234 - accuracy: 0.3696\n",
      "Epoch 15: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 1.3234 - accuracy: 0.3696 - val_loss: 1.3283 - val_accuracy: 0.3693\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3278 - accuracy: 0.3505\n",
      "Epoch 16: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 1.3278 - accuracy: 0.3505 - val_loss: 1.3294 - val_accuracy: 0.3693\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3173 - accuracy: 0.3750\n",
      "Epoch 17: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 1.3173 - accuracy: 0.3750 - val_loss: 1.3191 - val_accuracy: 0.3693\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3222 - accuracy: 0.3587\n",
      "Epoch 18: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3222 - accuracy: 0.3587 - val_loss: 1.3208 - val_accuracy: 0.3693\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3207 - accuracy: 0.3764\n",
      "Epoch 19: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 1.3207 - accuracy: 0.3764 - val_loss: 1.3142 - val_accuracy: 0.3693\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3054 - accuracy: 0.3764\n",
      "Epoch 20: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3054 - accuracy: 0.3764 - val_loss: 1.3145 - val_accuracy: 0.3693\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3236 - accuracy: 0.3587\n",
      "Epoch 21: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3236 - accuracy: 0.3587 - val_loss: 1.3170 - val_accuracy: 0.3693\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3085 - accuracy: 0.3736\n",
      "Epoch 22: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 1.3085 - accuracy: 0.3736 - val_loss: 1.3207 - val_accuracy: 0.3693\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3249 - accuracy: 0.3709\n",
      "Epoch 23: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 1.3249 - accuracy: 0.3709 - val_loss: 1.3174 - val_accuracy: 0.3693\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3186 - accuracy: 0.3736\n",
      "Epoch 24: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 1.3186 - accuracy: 0.3736 - val_loss: 1.3164 - val_accuracy: 0.3693\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3184 - accuracy: 0.3655\n",
      "Epoch 25: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3184 - accuracy: 0.3655 - val_loss: 1.3123 - val_accuracy: 0.3693\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3138 - accuracy: 0.3587\n",
      "Epoch 26: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 1.3138 - accuracy: 0.3587 - val_loss: 1.3132 - val_accuracy: 0.3693\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3252 - accuracy: 0.3655\n",
      "Epoch 27: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3252 - accuracy: 0.3655 - val_loss: 1.3132 - val_accuracy: 0.3693\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3152 - accuracy: 0.3832\n",
      "Epoch 28: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 1.3152 - accuracy: 0.3832 - val_loss: 1.3184 - val_accuracy: 0.3693\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3259 - accuracy: 0.3696\n",
      "Epoch 29: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3259 - accuracy: 0.3696 - val_loss: 1.3196 - val_accuracy: 0.3693\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3255 - accuracy: 0.3764\n",
      "Epoch 30: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3255 - accuracy: 0.3764 - val_loss: 1.3210 - val_accuracy: 0.3693\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3238 - accuracy: 0.3736\n",
      "Epoch 31: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3238 - accuracy: 0.3736 - val_loss: 1.3279 - val_accuracy: 0.3693\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3086 - accuracy: 0.3478\n",
      "Epoch 32: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3086 - accuracy: 0.3478 - val_loss: 1.3174 - val_accuracy: 0.3693\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3021 - accuracy: 0.3845\n",
      "Epoch 33: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3021 - accuracy: 0.3845 - val_loss: 1.3158 - val_accuracy: 0.3693\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3197 - accuracy: 0.3614\n",
      "Epoch 34: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3197 - accuracy: 0.3614 - val_loss: 1.3156 - val_accuracy: 0.3693\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3121 - accuracy: 0.3777\n",
      "Epoch 35: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3121 - accuracy: 0.3777 - val_loss: 1.3196 - val_accuracy: 0.3693\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3083 - accuracy: 0.3832\n",
      "Epoch 36: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 1.3083 - accuracy: 0.3832 - val_loss: 1.3218 - val_accuracy: 0.3693\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3007 - accuracy: 0.3859\n",
      "Epoch 37: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3007 - accuracy: 0.3859 - val_loss: 1.3121 - val_accuracy: 0.3693\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3275 - accuracy: 0.3315\n",
      "Epoch 38: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 720ms/step - loss: 1.3275 - accuracy: 0.3315 - val_loss: 1.3176 - val_accuracy: 0.3693\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3188 - accuracy: 0.3614\n",
      "Epoch 39: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 1.3188 - accuracy: 0.3614 - val_loss: 1.3142 - val_accuracy: 0.3693\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3156 - accuracy: 0.3723\n",
      "Epoch 40: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3156 - accuracy: 0.3723 - val_loss: 1.3180 - val_accuracy: 0.3693\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3100 - accuracy: 0.3764\n",
      "Epoch 41: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 1.3100 - accuracy: 0.3764 - val_loss: 1.3126 - val_accuracy: 0.3693\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3177 - accuracy: 0.3791\n",
      "Epoch 42: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 1.3177 - accuracy: 0.3791 - val_loss: 1.3147 - val_accuracy: 0.3693\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3228 - accuracy: 0.3709\n",
      "Epoch 43: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 1.3228 - accuracy: 0.3709 - val_loss: 1.3173 - val_accuracy: 0.3693\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3098 - accuracy: 0.3818\n",
      "Epoch 44: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3098 - accuracy: 0.3818 - val_loss: 1.3210 - val_accuracy: 0.3693\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3047 - accuracy: 0.3736\n",
      "Epoch 45: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 1.3047 - accuracy: 0.3736 - val_loss: 1.3154 - val_accuracy: 0.3693\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3061 - accuracy: 0.3913\n",
      "Epoch 46: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3061 - accuracy: 0.3913 - val_loss: 1.3143 - val_accuracy: 0.3693\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3127 - accuracy: 0.3696\n",
      "Epoch 47: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 1.3127 - accuracy: 0.3696 - val_loss: 1.3170 - val_accuracy: 0.3693\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3098 - accuracy: 0.3696\n",
      "Epoch 48: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3098 - accuracy: 0.3696 - val_loss: 1.3111 - val_accuracy: 0.3693\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3122 - accuracy: 0.3777\n",
      "Epoch 49: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3122 - accuracy: 0.3777 - val_loss: 1.3119 - val_accuracy: 0.3693\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3117 - accuracy: 0.3804\n",
      "Epoch 50: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3117 - accuracy: 0.3804 - val_loss: 1.3193 - val_accuracy: 0.3693\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3201 - accuracy: 0.3723\n",
      "Epoch 51: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3201 - accuracy: 0.3723 - val_loss: 1.3166 - val_accuracy: 0.3693\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2977 - accuracy: 0.3804\n",
      "Epoch 52: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.2977 - accuracy: 0.3804 - val_loss: 1.3175 - val_accuracy: 0.3693\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2996 - accuracy: 0.3832\n",
      "Epoch 53: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 1.2996 - accuracy: 0.3832 - val_loss: 1.3124 - val_accuracy: 0.3693\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3037 - accuracy: 0.3913\n",
      "Epoch 54: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 721ms/step - loss: 1.3037 - accuracy: 0.3913 - val_loss: 1.3120 - val_accuracy: 0.3693\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3176 - accuracy: 0.3709\n",
      "Epoch 55: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3176 - accuracy: 0.3709 - val_loss: 1.3104 - val_accuracy: 0.3693\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3187 - accuracy: 0.3750\n",
      "Epoch 56: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 1.3187 - accuracy: 0.3750 - val_loss: 1.3218 - val_accuracy: 0.3693\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3069 - accuracy: 0.3628\n",
      "Epoch 57: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3069 - accuracy: 0.3628 - val_loss: 1.3214 - val_accuracy: 0.3693\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3101 - accuracy: 0.3709\n",
      "Epoch 58: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 1.3101 - accuracy: 0.3709 - val_loss: 1.3173 - val_accuracy: 0.3693\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3170 - accuracy: 0.3764\n",
      "Epoch 59: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 1.3170 - accuracy: 0.3764 - val_loss: 1.3181 - val_accuracy: 0.3693\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3199 - accuracy: 0.3777\n",
      "Epoch 60: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3199 - accuracy: 0.3777 - val_loss: 1.3192 - val_accuracy: 0.3693\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3122 - accuracy: 0.3791\n",
      "Epoch 61: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3122 - accuracy: 0.3791 - val_loss: 1.3219 - val_accuracy: 0.3693\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3193 - accuracy: 0.3723\n",
      "Epoch 62: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3193 - accuracy: 0.3723 - val_loss: 1.3178 - val_accuracy: 0.3693\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2986 - accuracy: 0.3750\n",
      "Epoch 63: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 1.2986 - accuracy: 0.3750 - val_loss: 1.3125 - val_accuracy: 0.3693\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3108 - accuracy: 0.3791\n",
      "Epoch 64: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.3108 - accuracy: 0.3791 - val_loss: 1.3224 - val_accuracy: 0.3693\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3097 - accuracy: 0.3723\n",
      "Epoch 65: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3097 - accuracy: 0.3723 - val_loss: 1.3095 - val_accuracy: 0.3693\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2816 - accuracy: 0.3859\n",
      "Epoch 66: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 1.2816 - accuracy: 0.3859 - val_loss: 1.3081 - val_accuracy: 0.3693\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3024 - accuracy: 0.3845\n",
      "Epoch 67: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 1.3024 - accuracy: 0.3845 - val_loss: 1.3110 - val_accuracy: 0.3693\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2942 - accuracy: 0.3872\n",
      "Epoch 68: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.2942 - accuracy: 0.3872 - val_loss: 1.3093 - val_accuracy: 0.3693\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2828 - accuracy: 0.3723\n",
      "Epoch 69: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.2828 - accuracy: 0.3723 - val_loss: 1.3058 - val_accuracy: 0.3693\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2964 - accuracy: 0.3927\n",
      "Epoch 70: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.2964 - accuracy: 0.3927 - val_loss: 1.3109 - val_accuracy: 0.3693\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3208 - accuracy: 0.3614\n",
      "Epoch 71: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 1.3208 - accuracy: 0.3614 - val_loss: 1.3167 - val_accuracy: 0.3693\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3127 - accuracy: 0.3791\n",
      "Epoch 72: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.3127 - accuracy: 0.3791 - val_loss: 1.3173 - val_accuracy: 0.3693\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3128 - accuracy: 0.3723\n",
      "Epoch 73: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 1.3128 - accuracy: 0.3723 - val_loss: 1.3120 - val_accuracy: 0.3693\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3240 - accuracy: 0.3682\n",
      "Epoch 74: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 1.3240 - accuracy: 0.3682 - val_loss: 1.3154 - val_accuracy: 0.3693\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3144 - accuracy: 0.3804\n",
      "Epoch 75: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.3144 - accuracy: 0.3804 - val_loss: 1.3172 - val_accuracy: 0.3693\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3158 - accuracy: 0.3655\n",
      "Epoch 76: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 1.3158 - accuracy: 0.3655 - val_loss: 1.3133 - val_accuracy: 0.3693\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3200 - accuracy: 0.3832\n",
      "Epoch 77: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 1.3200 - accuracy: 0.3832 - val_loss: 1.3132 - val_accuracy: 0.3693\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3150 - accuracy: 0.3682\n",
      "Epoch 78: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 1.3150 - accuracy: 0.3682 - val_loss: 1.3140 - val_accuracy: 0.3693\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3174 - accuracy: 0.3723\n",
      "Epoch 79: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 1.3174 - accuracy: 0.3723 - val_loss: 1.3159 - val_accuracy: 0.3693\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3080 - accuracy: 0.3791\n",
      "Epoch 80: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 1.3080 - accuracy: 0.3791 - val_loss: 1.3113 - val_accuracy: 0.3693\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2985 - accuracy: 0.3818\n",
      "Epoch 81: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 1.2985 - accuracy: 0.3818 - val_loss: 1.3128 - val_accuracy: 0.3693\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3319 - accuracy: 0.3628\n",
      "Epoch 82: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 1.3319 - accuracy: 0.3628 - val_loss: 1.3146 - val_accuracy: 0.3693\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3019 - accuracy: 0.3736\n",
      "Epoch 83: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.3019 - accuracy: 0.3736 - val_loss: 1.3144 - val_accuracy: 0.3693\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3161 - accuracy: 0.3682\n",
      "Epoch 84: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.3161 - accuracy: 0.3682 - val_loss: 1.3162 - val_accuracy: 0.3693\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3138 - accuracy: 0.3764\n",
      "Epoch 85: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3138 - accuracy: 0.3764 - val_loss: 1.3088 - val_accuracy: 0.3693\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3073 - accuracy: 0.3709\n",
      "Epoch 86: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.3073 - accuracy: 0.3709 - val_loss: 1.3106 - val_accuracy: 0.3693\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3005 - accuracy: 0.3804\n",
      "Epoch 87: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.3005 - accuracy: 0.3804 - val_loss: 1.3108 - val_accuracy: 0.3693\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3160 - accuracy: 0.3791\n",
      "Epoch 88: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.3160 - accuracy: 0.3791 - val_loss: 1.3044 - val_accuracy: 0.3693\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3194 - accuracy: 0.3682\n",
      "Epoch 89: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3194 - accuracy: 0.3682 - val_loss: 1.3098 - val_accuracy: 0.3693\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3119 - accuracy: 0.3696\n",
      "Epoch 90: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3119 - accuracy: 0.3696 - val_loss: 1.3173 - val_accuracy: 0.3693\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2999 - accuracy: 0.3736\n",
      "Epoch 91: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 1.2999 - accuracy: 0.3736 - val_loss: 1.3164 - val_accuracy: 0.3693\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2895 - accuracy: 0.4062\n",
      "Epoch 92: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.2895 - accuracy: 0.4062 - val_loss: 1.3143 - val_accuracy: 0.3693\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3020 - accuracy: 0.3845\n",
      "Epoch 93: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 1.3020 - accuracy: 0.3845 - val_loss: 1.3110 - val_accuracy: 0.3693\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3120 - accuracy: 0.3859\n",
      "Epoch 94: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.3120 - accuracy: 0.3859 - val_loss: 1.3134 - val_accuracy: 0.3693\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3243 - accuracy: 0.3641\n",
      "Epoch 95: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 1.3243 - accuracy: 0.3641 - val_loss: 1.3138 - val_accuracy: 0.3693\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3008 - accuracy: 0.3818\n",
      "Epoch 96: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.3008 - accuracy: 0.3818 - val_loss: 1.3100 - val_accuracy: 0.3693\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3099 - accuracy: 0.3777\n",
      "Epoch 97: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 1.3099 - accuracy: 0.3777 - val_loss: 1.3141 - val_accuracy: 0.3693\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.2886 - accuracy: 0.3886\n",
      "Epoch 98: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.2886 - accuracy: 0.3886 - val_loss: 1.3113 - val_accuracy: 0.3693\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3331 - accuracy: 0.3560\n",
      "Epoch 99: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 1.3331 - accuracy: 0.3560 - val_loss: 1.3163 - val_accuracy: 0.3693\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.3168 - accuracy: 0.3804\n",
      "Epoch 100: val_accuracy did not improve from 0.36932\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 1.3168 - accuracy: 0.3804 - val_loss: 1.3111 - val_accuracy: 0.3693\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
