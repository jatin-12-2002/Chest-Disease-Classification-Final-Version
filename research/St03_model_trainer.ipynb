{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/project/research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/project'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    validation_data:Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chest-CT-Scan-data/Data/train\")\n",
    "        validation_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chest-CT-Scan-data/Data/valid\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            validation_data=Path(validation_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import shutil\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.applications import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32',\n",
    "                                                                    preprocessing_function=resnet.preprocess_input)\n",
    "        self.train_generator = train_datagen.flow_from_directory(self.config.training_data,\n",
    "                                                   batch_size = self.config.params_batch_size,\n",
    "                                                   target_size = self.config.params_image_size[:-1],\n",
    "                                                   class_mode = 'categorical')\n",
    "\n",
    "        valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32',\n",
    "                                                                    preprocessing_function=resnet.preprocess_input)\n",
    "        self.valid_generator = valid_datagen.flow_from_directory(self.config.validation_data,\n",
    "                                                   batch_size = self.config.params_batch_size,\n",
    "                                                   target_size = self.config.params_image_size[:-1],\n",
    "                                                   class_mode = 'categorical')\n",
    "\n",
    "        # if self.config.params_is_augmentation:\n",
    "        #     train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        #         rotation_range=40,\n",
    "        #         horizontal_flip=True,\n",
    "        #         width_shift_range=0.2,\n",
    "        #         height_shift_range=0.2,\n",
    "        #         shear_range=0.2,\n",
    "        #         zoom_range=0.2,\n",
    "        #         **datagenerator_kwargs\n",
    "        #     )\n",
    "        # else:\n",
    "        #     train_datagenerator = valid_datagenerator\n",
    "\n",
    "        # self.train_generator = train_datagenerator.flow_from_directory(\n",
    "        #     directory=self.config.training_data,\n",
    "        #     subset=\"training\",\n",
    "        #     shuffle=True,\n",
    "        #     **dataflow_kwargs\n",
    "        # )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "        \n",
    "        destination_dir = path.parent.parent.parent / \"model\"\n",
    "        if not destination_dir.exists():\n",
    "            destination_dir.mkdir(parents=True)\n",
    "\n",
    "        # Copy the file to the destination directory\n",
    "        destination_file = destination_dir / \"model.h5\"\n",
    "        shutil.copyfile(path, destination_file)\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.checkpointer = ModelCheckpoint(filepath=str(self.config.trained_model_path),\n",
    "                            monitor='val_loss', verbose = 1,\n",
    "                            save_best_only=True)\n",
    "        self.early_stopping = EarlyStopping(verbose=1, patience=15)\n",
    "        \n",
    "        self.model.fit(self.train_generator,\n",
    "                    steps_per_epoch = self.steps_per_epoch,\n",
    "                    epochs = self.config.params_epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = self.valid_generator,\n",
    "                    callbacks = [self.checkpointer, self.early_stopping])\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-02 23:17:01,107: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-04-02 23:17:01,110: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-04-02 23:17:01,111: INFO: common: created directory at: artifacts]\n",
      "[2024-04-02 23:17:01,111: INFO: common: created directory at: artifacts/training]\n",
      "Found 613 images belonging to 4 classes.\n",
      "Found 72 images belonging to 4 classes.\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 2.6238 - acc: 0.2814\n",
      "Epoch 1: val_loss improved from inf to 1.69032, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 227s 6s/step - loss: 2.6238 - acc: 0.2814 - val_loss: 1.6903 - val_acc: 0.2917\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 2.0634 - acc: 0.3769\n",
      "Epoch 2: val_loss improved from 1.69032 to 1.31077, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 222s 6s/step - loss: 2.0634 - acc: 0.3769 - val_loss: 1.3108 - val_acc: 0.3889\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.7203 - acc: 0.4338\n",
      "Epoch 3: val_loss improved from 1.31077 to 1.11429, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 227s 6s/step - loss: 1.7203 - acc: 0.4338 - val_loss: 1.1143 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.5437 - acc: 0.4824\n",
      "Epoch 4: val_loss improved from 1.11429 to 1.01088, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 224s 6s/step - loss: 1.5437 - acc: 0.4824 - val_loss: 1.0109 - val_acc: 0.5139\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.4476 - acc: 0.5193\n",
      "Epoch 5: val_loss improved from 1.01088 to 0.92769, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 256s 7s/step - loss: 1.4476 - acc: 0.5193 - val_loss: 0.9277 - val_acc: 0.5694\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.4873 - acc: 0.5209\n",
      "Epoch 6: val_loss improved from 0.92769 to 0.87250, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 222s 6s/step - loss: 1.4873 - acc: 0.5209 - val_loss: 0.8725 - val_acc: 0.5972\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.2440 - acc: 0.5745\n",
      "Epoch 7: val_loss improved from 0.87250 to 0.80967, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 222s 6s/step - loss: 1.2440 - acc: 0.5745 - val_loss: 0.8097 - val_acc: 0.6667\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.0314 - acc: 0.6348\n",
      "Epoch 8: val_loss improved from 0.80967 to 0.75132, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 225s 6s/step - loss: 1.0314 - acc: 0.6348 - val_loss: 0.7513 - val_acc: 0.7222\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9590 - acc: 0.6482\n",
      "Epoch 9: val_loss improved from 0.75132 to 0.72587, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 223s 6s/step - loss: 0.9590 - acc: 0.6482 - val_loss: 0.7259 - val_acc: 0.7639\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9818 - acc: 0.6466\n",
      "Epoch 10: val_loss improved from 0.72587 to 0.69072, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 228s 6s/step - loss: 0.9818 - acc: 0.6466 - val_loss: 0.6907 - val_acc: 0.7639\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8613 - acc: 0.6750\n",
      "Epoch 11: val_loss improved from 0.69072 to 0.66332, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 225s 6s/step - loss: 0.8613 - acc: 0.6750 - val_loss: 0.6633 - val_acc: 0.7917\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7747 - acc: 0.7303\n",
      "Epoch 12: val_loss improved from 0.66332 to 0.63336, saving model to artifacts/training/model.h5\n",
      "38/38 [==============================] - 223s 6s/step - loss: 0.7747 - acc: 0.7303 - val_loss: 0.6334 - val_acc: 0.8056\n",
      "Epoch 13/100\n",
      "18/38 [=============>................] - ETA: 1:44 - loss: 0.8110 - acc: 0.6931"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
